---
phase: 00-baseline-audit
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/routers/audit.py
  - app/services/audit_runner.py
  - app/services/firebase.py
  - app/main.py
autonomous: true
requirements:
  - BASE-01
  - BASE-02
  - BASE-03
  - BASE-04

must_haves:
  truths:
    - "POST /audit returns 200 and triggers the full parameter matrix run synchronously"
    - "Audit iterates outer loop over 3 quantization variants (Q4_0, Q5_K_S, Q8_0), inner loop over 5 guidance values (2, 4, 10, 20, 30)"
    - "Each inference result is uploaded to Firebase Storage under audit/{run_id}/"
    - "VRAM is freed between quantization variants (del + gc.collect + cuda.empty_cache)"
    - "Wall-clock and CUDA-event GPU timing are recorded per inference"
    - "torch._dynamo.explain() is run on the transformer and break count + reasons are captured"
    - "A Markdown audit report is uploaded to Firebase Storage with signed URLs, timing table, GPU identity, and torch.compile viability section"
  artifacts:
    - path: "app/routers/audit.py"
      provides: "POST /audit endpoint that accepts {user_id, session_id, run_id} and calls audit_runner"
      min_lines: 30
    - path: "app/services/audit_runner.py"
      provides: "run_audit() orchestrates quant loop, guidance loop, CUDA timing, VRAM cleanup, dynamo explain, report generation"
      min_lines: 150
    - path: "app/services/firebase.py"
      provides: "generate_signed_url() helper added alongside existing upload_blob"
      contains: "generate_signed_url"
    - path: "app/main.py"
      provides: "audit router imported and registered"
      contains: "audit_router"
  key_links:
    - from: "app/routers/audit.py"
      to: "app/services/audit_runner.py"
      via: "import run_audit; call in route handler"
      pattern: "run_audit"
    - from: "app/services/audit_runner.py"
      to: "FluxTransformer2DModel.from_single_file"
      via: "hf_hub_download returns local path, passed to from_single_file"
      pattern: "hf_hub_download"
    - from: "app/services/audit_runner.py"
      to: "app/services/firebase.py"
      via: "upload_blob for images, generate_signed_url for report links"
      pattern: "generate_signed_url"
---

<objective>
Implement the audit endpoint and parameter matrix runner that forms the core of Phase 0.

Purpose: Enable a single HTTP call to run all parameter variations (3 quants × 5 guidance values = 15 inferences) on reference session D1A406F5, capture CUDA timing, check torch.compile viability, upload all outputs to Firebase Storage, and produce a Markdown report.

Output:
- app/routers/audit.py — POST /audit endpoint
- app/services/audit_runner.py — full matrix execution + report generation
- app/services/firebase.py — generate_signed_url() helper added
- app/main.py — audit router registered
</objective>

<execution_context>
@/Users/colinwatson/.claude/get-shit-done/workflows/execute-plan.md
@/Users/colinwatson/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/00-baseline-audit/00-CONTEXT.md
@.planning/phases/00-baseline-audit/00-RESEARCH.md
@app/services/flux_inpaint.py
@app/services/firebase.py
@app/services/pipeline.py
@app/main.py
@app/routers/inpaint.py
@Dockerfile
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add generate_signed_url helper to firebase.py and register audit router in main.py</name>
  <files>app/services/firebase.py
app/main.py</files>
  <action>
In app/services/firebase.py, add a generate_signed_url() function after the existing upload_blob function:

```python
import datetime

def generate_signed_url(path: str, expiry_hours: int = 72) -> str:
    """Generate a V4 signed URL for a Firebase Storage blob."""
    bucket = get_storage_bucket()
    blob = bucket.blob(path)
    url = blob.generate_signed_url(
        version="v4",
        expiration=datetime.timedelta(hours=expiry_hours),
        method="GET",
    )
    return url
```

Note: `datetime` must be imported at the top. The existing `import` block already has `logging`, `os`, etc. — add `import datetime` there. Do NOT add a new top-level `import datetime` inline — put it with the other stdlib imports at the top of the file.

Also add an upload_and_sign() convenience function that uploads bytes and returns a signed URL:

```python
def upload_and_sign(path: str, data: bytes, content_type: str, expiry_hours: int = 72) -> str:
    """Upload bytes to Firebase Storage and return a signed URL."""
    upload_blob(path, data, content_type)
    return generate_signed_url(path, expiry_hours)
```

In app/main.py, add the audit router import and registration after the existing inpaint router. Add it at the bottom of the file following the same pattern as the inpaint router:

```python
from app.routers.audit import router as audit_router  # noqa: E402
app.include_router(audit_router)
```

The audit router does not exist yet (created in Task 2) — that's fine. The import will resolve once Task 2 creates it.
  </action>
  <verify>
python3 -c "import ast; ast.parse(open('app/services/firebase.py').read()); print('firebase.py syntax OK')"
python3 -c "import ast; ast.parse(open('app/main.py').read()); print('main.py syntax OK')"
grep -n "generate_signed_url" app/services/firebase.py
grep -n "upload_and_sign" app/services/firebase.py
grep -n "audit_router" app/main.py
  </verify>
  <done>
firebase.py has generate_signed_url() and upload_and_sign() functions, both syntactically valid.
main.py imports and registers the audit router at the bottom.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement audit_runner.py and audit.py router</name>
  <files>app/services/audit_runner.py
app/routers/audit.py</files>
  <action>
Create app/services/audit_runner.py. This is the core audit engine. Implement run_audit(user_id, session_id, run_id) that:

**Imports (use these exact libraries — all already in pyproject.toml):**
```python
import gc
import io
import logging
import time
from datetime import datetime
from typing import Any

import torch
import torch._dynamo as dynamo
from diffusers import FluxFillPipeline, FluxTransformer2DModel, GGUFQuantizationConfig
from huggingface_hub import hf_hub_download

from app.services import firebase
from app.utils.image import decode_image, decode_mask, resize_for_flux
```

**Constants at module top:**
```python
logger = logging.getLogger(__name__)

REFERENCE_SESSION_PROMPT = "empty ground, nothing here, just the natural ground surface continuing seamlessly"
NUM_STEPS = 28  # held constant for quant and guidance tests

# Quantization variants: (label, HF filename)
# Q5_K_M does not exist in YarvixPA repo — use Q5_K_S (8.29 GB)
QUANT_VARIANTS = [
    ("Q4_0", "flux1-fill-dev-Q4_0.gguf"),
    ("Q5_K_S", "flux1-fill-dev-Q5_K_S.gguf"),
    ("Q8_0", "flux1-fill-dev-Q8_0.gguf"),
]

# Guidance scale grid (covers full disagreement range: official=30, community fill=2-5, current prod=10)
GUIDANCE_SCALE_GRID = [2, 4, 10, 20, 30]

HF_REPO = "YarvixPA/FLUX.1-Fill-dev-GGUF"
PIPELINE_PRETRAINED = "black-forest-labs/FLUX.1-Fill-dev"
```

**Core run_audit() function:**

```python
def run_audit(user_id: str, session_id: str, run_id: str) -> dict[str, Any]:
```

Steps inside run_audit():

1. **Confirm GPU identity** — at the very start, log and record:
   ```python
   gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU"
   if torch.cuda.is_available():
       major, minor = torch.cuda.get_device_capability(0)
       sm = f"sm_{major}{minor}"
       total_vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9
   else:
       sm = "N/A"
       total_vram_gb = 0.0
   logger.info(f"GPU: {gpu_name}, compute capability: {sm}, VRAM: {total_vram_gb:.1f} GB")
   ```

2. **Download session assets from Firebase Storage** — use existing firebase.download_blob():
   ```python
   base_path = f"users/{user_id}/sessions/{session_id}"
   image_bytes = firebase.download_blob(f"{base_path}/original.jpg")
   mask_bytes = firebase.download_blob(f"{base_path}/mask_auto.png")
   ```
   Then decode and resize using existing image utils (decode_image, decode_mask, resize_for_flux).

3. **Run parameter matrix** — outer loop over QUANT_VARIANTS, inner loop over GUIDANCE_SCALE_GRID:
   - For each quantization variant:
     a. Download GGUF via hf_hub_download (returns local cache path — fast if already cached, downloads if not):
        ```python
        local_gguf = hf_hub_download(repo_id=HF_REPO, filename=gguf_filename)
        ```
     b. Load transformer:
        ```python
        transformer = FluxTransformer2DModel.from_single_file(
            local_gguf,
            quantization_config=GGUFQuantizationConfig(compute_dtype=torch.bfloat16),
            torch_dtype=torch.bfloat16,
        )
        ```
     c. Load pipeline:
        ```python
        pipe = FluxFillPipeline.from_pretrained(
            PIPELINE_PRETRAINED,
            transformer=transformer,
            torch_dtype=torch.bfloat16,
        )
        pipe.enable_model_cpu_offload()
        ```
     d. For each guidance_scale in GUIDANCE_SCALE_GRID:
        - Time with BOTH wall-clock (time.time()) AND CUDA events:
          ```python
          start_wall = time.time()
          start_evt = torch.cuda.Event(enable_timing=True)
          end_evt = torch.cuda.Event(enable_timing=True)
          start_evt.record()
          result = pipe(
              prompt=REFERENCE_SESSION_PROMPT,
              image=image_resized,
              mask_image=mask_resized,
              num_inference_steps=NUM_STEPS,
              guidance_scale=gs,
          )
          end_evt.record()
          torch.cuda.synchronize()
          wall_s = time.time() - start_wall
          gpu_ms = start_evt.elapsed_time(end_evt)
          ```
        - Save image to PNG bytes (use PIL: `img.save(buf, format="PNG")`)
        - Upload to Firebase Storage at `audit/{run_id}/{quant_label}_gs{gs:.0f}.png`
        - Generate signed URL via firebase.generate_signed_url()
        - Append result dict to results list: `{"quant": quant_label, "guidance": gs, "steps": NUM_STEPS, "wall_s": wall_s, "gpu_ms": gpu_ms, "image_path": storage_path, "signed_url": url}`
     e. VRAM cleanup after each quantization group:
        ```python
        del transformer
        del pipe
        gc.collect()
        torch.cuda.empty_cache()
        reserved = torch.cuda.memory_reserved(0) / 1e9
        logger.info(f"VRAM after cleanup: {reserved:.1f} GB reserved")
        ```

4. **torch.compile viability check** — run AFTER the matrix (don't pollute timing):
   - Load Q4_0 (lightest quant) just for the compile check:
     ```python
     local_gguf = hf_hub_download(repo_id=HF_REPO, filename="flux1-fill-dev-Q4_0.gguf")
     transformer = FluxTransformer2DModel.from_single_file(local_gguf, ...)
     pipe_for_compile = FluxFillPipeline.from_pretrained(PIPELINE_PRETRAINED, transformer=transformer, ...)
     pipe_for_compile.enable_model_cpu_offload()
     ```
   - Run dynamo.explain() on a wrapped forward call:
     ```python
     dynamo.reset()

     def _test_forward():
         with torch.no_grad():
             return pipe_for_compile(
                 prompt=REFERENCE_SESSION_PROMPT,
                 image=image_resized,
                 mask_image=mask_resized,
                 num_inference_steps=1,  # minimal — just to trace
                 guidance_scale=4.0,
             )

     explanation = dynamo.explain(_test_forward)()
     compile_graph_count = explanation.graph_count
     compile_break_count = explanation.graph_break_count
     compile_break_reasons = [str(r) for r in explanation.break_reasons[:5]]  # cap at 5
     compile_viable = compile_break_count == 0
     compile_recommendation = (
         "Proceed with torch.compile in Phase 4 — zero graph breaks detected"
         if compile_viable
         else f"torch.compile has {compile_break_count} graph break(s) — review break reasons before Phase 4"
     )
     ```
   - Cleanup: `del transformer; del pipe_for_compile; gc.collect(); torch.cuda.empty_cache()`

5. **Generate Markdown report** — build a string with this structure:
   ```markdown
   # Baseline Audit Report — {run_id}
   **Session:** {session_id} | **Date:** {date} | **GPU:** {gpu_name} ({sm})

   ## GPU Info
   - Device: {gpu_name}
   - Compute Capability: {sm}
   - VRAM: {total_vram_gb:.1f} GB

   ## Results Matrix

   | Quant | Guidance | Steps | Wall-clock (s) | GPU time (ms) | Image |
   |-------|----------|-------|----------------|---------------|-------|
   {one row per result, with [view](signed_url) links}

   ## torch.compile Viability
   - Graph breaks detected: {compile_break_count}
   - Graph count: {compile_graph_count}
   - Break reasons: {compile_break_reasons or "None"}
   - Recommendation: {compile_recommendation}

   ## Recommended Settings for Phase 1
   *(Review images above and fill in)*
   - Best quantization variant:
   - Best guidance scale:
   - Notes:
   ```

   Upload report as `audit/{run_id}/REPORT.md` (content_type="text/markdown").
   Generate signed URL for the report blob.

6. **Return** a dict:
   ```python
   return {
       "run_id": run_id,
       "gpu": gpu_name,
       "sm": sm,
       "results": results,
       "compile_viable": compile_viable,
       "report_url": report_signed_url,
       "report_path": f"audit/{run_id}/REPORT.md",
   }
   ```

---

Create app/routers/audit.py:

```python
import logging
import uuid

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

from app.services.audit_runner import run_audit

logger = logging.getLogger(__name__)

router = APIRouter()


class AuditRequest(BaseModel):
    user_id: str
    session_id: str
    run_id: str | None = None  # auto-generated if not provided


@router.post("/audit")
def handle_audit(req: AuditRequest):
    """
    Trigger a full baseline audit run.
    Synchronous — runs the full matrix (3 quants × 5 guidance = 15 inferences + compile check).
    Estimated duration: 25-60 minutes on L4.
    Set client timeout accordingly (e.g., curl --max-time 7200).
    """
    run_id = req.run_id or f"audit-{uuid.uuid4().hex[:8]}"
    logger.info(f"Starting audit run: run_id={run_id}, session={req.session_id}")

    try:
        result = run_audit(req.user_id, req.session_id, run_id)
        logger.info(f"Audit complete: run_id={run_id}, report={result['report_path']}")
        return {
            "status": "complete",
            "run_id": run_id,
            "report_url": result["report_url"],
            "report_path": result["report_path"],
            "gpu": result["gpu"],
            "sm": result["sm"],
            "compile_viable": result["compile_viable"],
            "result_count": len(result["results"]),
        }
    except Exception as e:
        logger.exception(f"Audit failed: run_id={run_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

Note: The route handler is synchronous (`def`, not `async def`) — FastAPI will run it in a thread pool automatically, which is correct for this long-running CPU/GPU task.
  </action>
  <verify>
python3 -c "import ast; ast.parse(open('app/services/audit_runner.py').read()); print('audit_runner.py syntax OK')"
python3 -c "import ast; ast.parse(open('app/routers/audit.py').read()); print('audit.py syntax OK')"
grep -n "run_audit" app/services/audit_runner.py | head -5
grep -n "generate_signed_url\|upload_and_sign" app/services/audit_runner.py
grep -n "torch.cuda.synchronize\|elapsed_time" app/services/audit_runner.py
grep -n "dynamo.explain\|graph_break_count" app/services/audit_runner.py
grep -n "del transformer\|cuda.empty_cache" app/services/audit_runner.py
grep -c "QUANT_VARIANTS\|GUIDANCE_SCALE_GRID" app/services/audit_runner.py
  </verify>
  <done>
audit_runner.py is syntactically valid and contains: run_audit() function, QUANT_VARIANTS with Q4_0/Q5_K_S/Q8_0, GUIDANCE_SCALE_GRID with 5 values, CUDA event timing, dynamo.explain() call, VRAM cleanup pattern, Markdown report generation, Firebase Storage upload.
audit.py router is syntactically valid with POST /audit endpoint accepting AuditRequest.
  </done>
</task>

</tasks>

<verification>
After both tasks complete:
1. python3 -c "import ast; [ast.parse(open(f).read()) for f in ['app/services/firebase.py', 'app/services/audit_runner.py', 'app/routers/audit.py', 'app/main.py']]; print('All files syntax OK')"
2. grep -n "audit_router" app/main.py — confirms router registered
3. grep -n "generate_signed_url\|upload_and_sign" app/services/firebase.py — confirms helper added
4. grep -n "QUANT_VARIANTS" app/services/audit_runner.py — confirms 3 quant variants defined
5. grep -n "GUIDANCE_SCALE_GRID" app/services/audit_runner.py — confirms 5 guidance values
6. grep -n "dynamo.explain" app/services/audit_runner.py — confirms compile check present
7. grep -n "cuda.empty_cache" app/services/audit_runner.py — confirms VRAM cleanup
</verification>

<success_criteria>
- All 4 modified/created files pass Python syntax check
- audit_runner.py implements: GPU identity logging, session asset download, 3-quant × 5-guidance matrix, dual timing (wall-clock + CUDA events), VRAM cleanup between quant groups, torch.compile viability check via dynamo.explain(), Markdown report generation with signed URLs
- audit.py router exposes POST /audit accepting {user_id, session_id, run_id}
- firebase.py has generate_signed_url() and upload_and_sign() helpers
- main.py registers the audit router
- No new dependencies added (all imports are already in pyproject.toml or stdlib)
</success_criteria>

<output>
After completion, create `.planning/phases/00-baseline-audit/00-01-SUMMARY.md`
</output>
